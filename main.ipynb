{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bbd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_text(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"文本预处理：清洗、分句、去除无关字符\"\"\"\n",
    "    # 分句\n",
    "    sentences = re.split(r'(?<=[。！？\\?])', text)\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 5]\n",
    "    \n",
    "    # 清洗\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # 去除引号、括号等字符\n",
    "        cleaned = re.sub(r'[《》“”\\n（）()]', '', sentence)\n",
    "        cleaned_sentences.append(cleaned)\n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87935622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['据外媒报道，美国两架海军军机26日分别坠毁在南海，无人员伤亡。',\n",
       " '第一起坠机事件涉及一架MH-60R海鹰直升机。',\n",
       " '根据美国海军太平洋舰队的声明，这架直升机在尼米兹号航空母舰进行例行操作时坠入南海。',\n",
       " '声明称，直升机上的三名机组人员被搜救队救起。',\n",
       " '半小时后，一架波音F/A-18F超级大黄蜂战斗机在尼米兹号航空母舰执行例行任务时也坠毁在南海。',\n",
       " '机上两名机组人员成功弹射逃生，被安全救起。',\n",
       " '据美国海军称，所有相关人员均安全且情况稳定。',\n",
       " '两起事故原因正在调查中。',\n",
       " ' 军事专家张军社27日接受环球时报采访时表示，美国在南海一天内先后坠毁一架舰载战斗机和一架直升机，这一事件并非偶然。',\n",
       " '美军长期在南海、亚太及全球范围内维持高强度战备状态，不断进行军事部署，以维持其霸权地位和国际警察角色。',\n",
       " '长期高压运作使美军兵力紧张、人员疲惫，事故发生的风险自然随之上升。',\n",
       " '他认为，此次事故很可能与操作疏忽或过度疲劳等因素有关。',\n",
       " '军事专家宋忠平27日接受环球时报采访时也持相似观点。',\n",
       " '他指出，美军长期以所谓航行自由为借口，在南海频繁炫耀武力，意在彰显其军事存在。',\n",
       " '表面上看，美国作为军事霸主仍在维持强势姿态，但实际上，即便拥有11 艘航空母舰，面对如此繁重的任务，美军也已力不从心。',\n",
       " '宋忠平分析称，美军航母肩负全球部署和多重任务，长期在中东及其他地区高强度执行作战和训练，加之部分官兵存在懈怠、厌战情绪，导致安全风险上升。',\n",
       " '因此，同一天发生两起坠机事故虽令人震惊，但并不令人意外。']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = read_text(\"text1.txt\")\n",
    "preprocess_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50746015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class DependencyTripleExtractor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"zh_core_web_sm\")\n",
    "        \n",
    "        # 初始化关系映射规则\n",
    "        self.init_relation_relus()\n",
    "\n",
    "    def init_relation_relus(self):\n",
    "        \"\"\"初始化依存关系到语义关系的映射规则\"\"\"\n",
    "        # 基础依存关系映射\n",
    "        self.dep_to_relation = {\n",
    "            'nsubj': '',  # 主语，使用动词本身\n",
    "            'dobj': '',   # 宾语，使用动词本身\n",
    "            'nmod:poss': '的',  # 属格关系\n",
    "            'prep': '',   # 介词，与动词组合\n",
    "            'pobj': '',   # 介词宾语\n",
    "            'appos': '是',  # 同位语关系\n",
    "            'amod': '',   # 形容词修饰\n",
    "            'nummod': ''  # 数量修饰\n",
    "        }\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"文本预处理：清洗、分句、去除无关字符\"\"\"\n",
    "        # 分句\n",
    "        sentences = re.split(r'(?<=[。！？\\?])', text)\n",
    "        sentences = [s.strip() for s in sentences if len(s.strip()) > 5]\n",
    "        \n",
    "        # 清洗\n",
    "        cleaned_sentences = []\n",
    "        for sentence in sentences:\n",
    "            # 去除引号、括号等字符\n",
    "            cleaned = re.sub(r'[《》“”\\n（）()]', '', sentence)\n",
    "            cleaned_sentences.append(cleaned)\n",
    "        return cleaned_sentences\n",
    "    \n",
    "    def analyze_sentence(self, sentence):\n",
    "        \"\"\"分析句子结构：分词、词性标注、依存句法分析\"\"\"\n",
    "        # 实验spacy进行依存分析\n",
    "        doc = self.nlp(sentence)\n",
    "\n",
    "        # 构建依存关系图\n",
    "        dependency_info = []\n",
    "        root_token = None\n",
    "        for token in doc:\n",
    "            dep_info = {\n",
    "                'text': token.text,\n",
    "                'lemma': token.lemma_,\n",
    "                'pos': token.pos_,\n",
    "                'dep': token.dep_,\n",
    "                'head_text': token.head.text,\n",
    "                'head_pos': token.head.pos_,\n",
    "                'is_root': token.dep == 'ROOT'\n",
    "            }\n",
    "            dependency_info.append(dep_info)\n",
    "            if token.dep == 'ROOT':\n",
    "                root_token = token\n",
    "        return doc, dependency_info, root_token\n",
    "\n",
    "    def extract_triples_by_rules(self, doc, root_token):\n",
    "        \"\"\"基于规则的三元组抽取\"\"\"\n",
    "        triples = []\n",
    "\n",
    "        # 规则1：主谓宾结构\n",
    "        svo_triples = self.extract_svo_triples(doc, root_token)\n",
    "        triples.extend(svo_triples)\n",
    "\n",
    "        # 规则2：介词结构\n",
    "        prep_triples = self.extract_preposition_triples(doc)\n",
    "        triples.extend(prep_triples)\n",
    "\n",
    "        # 规则3：属格关系\n",
    "        poss_triples = self.extract_possessive_triples(doc)\n",
    "        triples.extend(poss_triples)\n",
    "\n",
    "        # 规则4：同位语关系\n",
    "        appos_triples = self.extract_appos_triples(doc)\n",
    "        triples.extend(appos_triples)\n",
    "\n",
    "        return triples\n",
    "    \n",
    "    def extract_svo_triples(self, doc, root_token):\n",
    "        \"\"\"抽取主谓宾结构的三元组\"\"\"\n",
    "        triples = []\n",
    "        # 找到所有动词\n",
    "        verbs = [token for token in doc if token.pos_ == 'VERB']\n",
    "        if not verbs and root_token:\n",
    "            verbs = [root_token]\n",
    "        \n",
    "        for verb in verbs:\n",
    "            # 寻找主语\n",
    "            subjects = []\n",
    "            for child in verb.children:\n",
    "                if child.dep_ in ['nsubj', 'nsubj:pass']:\n",
    "                    subjects.append(child)\n",
    "            \n",
    "            # 寻找宾语\n",
    "            objects = []\n",
    "            for child in verb.children:\n",
    "                if child.dep_ in ['dobj', 'obj']:\n",
    "                    objects.append(child)\n",
    "                elif child.dep_ == 'prep':\n",
    "                    objects.append(child)\n",
    "            \n",
    "            # 生成三元组\n",
    "            for subject in subjects:\n",
    "                for object in objects:\n",
    "                    # 获取完整的短语\n",
    "                    subject_phrase = self.get_complete_phrase(subject)\n",
    "                    object_phrase = self.get_complete_phrase(object)\n",
    "                    relation = verb.text\n",
    "\n",
    "                    # 验证是否合理\n",
    "                    if self.is_valid_triple(subject_phrase, relation, object_phrase):\n",
    "                        triple = {\n",
    "                            'subject': subject_phrase,\n",
    "                            'relation': relation,\n",
    "                            'object': object_phrase,\n",
    "                            'subject_type': self.classify_entity_type(subject),\n",
    "                            'object_type': self.classify_entity_type(object),\n",
    "                            'confidence': 0.8,\n",
    "                            'rule': 'SVO'\n",
    "                        }\n",
    "                        triples.append(triple)\n",
    "        return triples\n",
    "    \n",
    "    def extract_preposition_triples(self, doc):\n",
    "        \"\"\"抽取介词结构和三元组\"\"\"\n",
    "        triples = []\n",
    "        # 找到所有介词\n",
    "        prepositions = [token for token in doc if token.dep_ in ['prep', 'case']]\n",
    "\n",
    "        for prep in prepositions:\n",
    "            head = prep.head\n",
    "            # 寻找介词的宾语\n",
    "            pobjects = []\n",
    "            # 1. 直接查找 pobj 关系\n",
    "            for child in prep.children:\n",
    "                if child.dep_ == 'pobj':\n",
    "                    pobjects.append(child)\n",
    "            \n",
    "            # 2. 如果介词是case关系，其父节点就是宾语的核心\n",
    "            if prep.dep_ == 'case' and not pobjects:\n",
    "                # prep.head 就是宾语的核心词\n",
    "                # 找到以核心词为根的完整名词短语\n",
    "                if head.pos_ != 'VERB':\n",
    "                    pobjects.append(head)\n",
    "            # 3. 查找其他可能的宾语关系\n",
    "            if not pobjects:\n",
    "                for child in head.children:\n",
    "                    if child.dep_ in ['dobj', 'obj', 'nmod']:\n",
    "                        pobjects.append(child)\n",
    "            \n",
    "            for pobj in pobjects:\n",
    "                # 确定关系动词\n",
    "                verb = None\n",
    "                # 1. 介词依附于动词\n",
    "                if head.pos_ == 'VERB':\n",
    "                    verb = head\n",
    "                else: # 2. 寻找包含这个介词结构的短语\n",
    "                    # 向上查找动词祖先\n",
    "                    current = head\n",
    "                    while current.head != current:  \n",
    "                        if current.head.pos_ == 'VERB':\n",
    "                            verb = current.head\n",
    "                            break\n",
    "                        current = current.head\n",
    "                if verb:\n",
    "                    # 寻找动词的主语\n",
    "                    subjects = [child for child in verb.children if child.dep_ in ['nsubj', 'nusbj:pass']]\n",
    "                    # 如果找不到主语，尝试查找话题主语\n",
    "                    if not subjects:\n",
    "                        for child in verb.children:\n",
    "                            if child.dep_ in ['csubj']:\n",
    "                                subjects.append(child)\n",
    "                    \n",
    "                    for subject in subjects:\n",
    "                        subject_phrase = self.get_complete_phrase(subject)\n",
    "                        object_phrase = self.get_complete_phrase(pobj)\n",
    "                        # 关系 = 动词 + 介词\n",
    "                        relation = f\"{verb.text}{prep.text}\"\n",
    "                        # 验证三元组是否合理\n",
    "                        if self.is_valid_triple(subject_phrase, relation, object_phrase):\n",
    "                            triple = {\n",
    "                                'subject': subject_phrase,\n",
    "                                'relation': relation,\n",
    "                                'object': object_phrase,\n",
    "                                'subject_type': self.classify_entity_type(subject),\n",
    "                                'object_type': self.classify_entity_type(pobj),\n",
    "                                'confidence': 0.7,\n",
    "                                'rule': 'PREP',\n",
    "                                'preposition': prep.text,\n",
    "                                'verb': verb.text\n",
    "                            }\n",
    "                            triples.append(triple)\n",
    "        return triples \n",
    "\n",
    "\n",
    "    def extract_possessive_triples(self, doc):\n",
    "        \"\"\"抽取属格关系的三元组\"\"\"\n",
    "        triples = []\n",
    "        # 找到所有属格关系\n",
    "        poss_relations = [token for token in doc if token.dep_ in ['poss', 'nmod:poss']]\n",
    "        \n",
    "        for poss in poss_relations:\n",
    "            possessor = poss # 拥有者\n",
    "            possessed = poss.head # 被拥有物\n",
    "\n",
    "            possessor_phrase = self.get_complete_phrase(possessor)\n",
    "            possessed_phrase = self.get_complete_phrase(possessed)\n",
    "            # 使用“的”关系\n",
    "            relation = \"的\"\n",
    "            if self.is_valid_triple(possessor_phrase, relation, possessed_phrase):\n",
    "                triples = {\n",
    "                    'subject': possessor_phrase,\n",
    "                    'relation': relation,\n",
    "                    'object': possessed_phrase,\n",
    "                    'subject_type': self.classify_entity_type(possessor),\n",
    "                    'object_type': self.classify_entity_type(possessed),\n",
    "                    'confidence': 0.9,\n",
    "                    'rule': 'POSS'\n",
    "                }\n",
    "                triples.append(triples)\n",
    "        return triples\n",
    "    \n",
    "    def extract_appos_triples(self, doc):\n",
    "        \"\"\"\n",
    "        抽取同位语关系的三元组\n",
    "        \"\"\"\n",
    "        triples = []\n",
    "        \n",
    "        # 找到所有同位语关系\n",
    "        appos_relations = [token for token in doc if token.dep_ == 'appos']\n",
    "        \n",
    "        for appos in appos_relations:\n",
    "            entity1 = appos  # 同位语\n",
    "            entity2 = appos.head  # 主要实体\n",
    "            \n",
    "            entity1_phrase = self.get_complete_phrase(entity1)\n",
    "            entity2_phrase = self.get_complete_phrase(entity2)\n",
    "            \n",
    "            relation = \"是\"\n",
    "            \n",
    "            if self.is_valid_triple(entity1_phrase, relation, entity2_phrase):\n",
    "                triple = {\n",
    "                    'subject': entity1_phrase,\n",
    "                    'relation': relation,\n",
    "                    'object': entity2_phrase,\n",
    "                    'subject_type': self.classify_entity_type(entity1),\n",
    "                    'object_type': self.classify_entity_type(entity2),\n",
    "                    'confidence': 0.85,\n",
    "                    'rule': 'APPOS'\n",
    "                }\n",
    "                triples.append(triple)\n",
    "        \n",
    "        return triples\n",
    "\n",
    "    def get_complete_phrase(self, token):\n",
    "        \"\"\"获取完整的短语\"\"\"\n",
    "        phrase_tokens = []\n",
    "        \n",
    "        # 使用栈进行深度优先遍历\n",
    "        stack = [token]\n",
    "        visited = set()\n",
    "\n",
    "        while stack:\n",
    "            current_token = stack.pop()\n",
    "            if current_token.i in visited:\n",
    "                continue\n",
    "            visited.add(current_token.i)\n",
    "            # 添加当前token\n",
    "            phrase_tokens.append((current_token.i, current_token.text))\n",
    "            # 添加所有修饰当前token的子节点\n",
    "            for child in current_token.children:\n",
    "                if child.dep_ in ['amod', 'nummod', 'compound', 'nmod']:\n",
    "                    stack.append(child)\n",
    "        \n",
    "        # 按原始顺序排序并组合\n",
    "        phrase_tokens.sort(key=lambda x: x[0])\n",
    "        phrase = ''.join([text for _, text in phrase_tokens])\n",
    "\n",
    "        return phrase\n",
    "\n",
    "\n",
    "    def optimize_relation(self, relation, rule_type):\n",
    "        \"\"\"\n",
    "        基于领域知识优化关系表达\n",
    "        \"\"\"\n",
    "        # 首先检查军事领域特定映射\n",
    "        if relation in self.military_relation_map:\n",
    "            return self.military_relation_map[relation]\n",
    "        \n",
    "        # 移除停用词\n",
    "        stop_words = {'了', '的', '在', '是', '有', '着', '过'}\n",
    "        for word in stop_words:\n",
    "            relation = relation.replace(word, '')\n",
    "        \n",
    "        return relation.strip()\n",
    "    \n",
    "    def classify_entity_type(self, token):\n",
    "        \"\"\"基于词性和依存关系分类实体类型\"\"\"\n",
    "\n",
    "        if token.pos_ in ['PROPN']: # 专有名词\n",
    "            return 'ENTITY'\n",
    "        elif token.pos_ == 'NOUN': # 普通名词\n",
    "            return 'NOUN'\n",
    "        elif token.pos_ == 'VERB': # 动词\n",
    "            return 'ACTION'\n",
    "        elif token.ent_type_ != '': # 已识别的实体类型\n",
    "            return token.ent_type_\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    def is_valid_triple(self, subject, relation, object):\n",
    "        \"\"\"验证三元组的有效性\"\"\"\n",
    "        # 检查长度\n",
    "        if len(subject) < 2 or len(object) < 2:\n",
    "            return False\n",
    "        # 检查关系有效性\n",
    "        if len(relation) == 0 or relation in ['', ' ']:\n",
    "            return False\n",
    "        # 检查是否为无意义的组合\n",
    "        meaningless = ['是是', '的的', '在在']\n",
    "        for m in meaningless:\n",
    "            if m in (subject + relation + object):\n",
    "                return False\n",
    "        # 代词/指示词过滤（单独作为实体不够具体）\n",
    "        # pronouns = {'他','她','它','他们','我们','你','我','这','该','其','它们','这里','那里','这些','那些','这个','那个'}\n",
    "        # if subject in pronouns or object in pronouns:\n",
    "        #     return False\n",
    "        # 检查主体和客体是否相同\n",
    "        if subject == object:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def post_process_triples(self, triples):\n",
    "        \"\"\"\n",
    "        后处理：去重、排序、过滤\n",
    "        \"\"\"\n",
    "        # 去重\n",
    "        seen = set()\n",
    "        unique_triples = []\n",
    "        \n",
    "        for triple in triples:\n",
    "            # 创建唯一标识\n",
    "            key = (triple['subject'], triple['relation'], triple['object'])\n",
    "            \n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                unique_triples.append(triple)\n",
    "        \n",
    "        # 按置信度排序\n",
    "        unique_triples.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        return unique_triples\n",
    "    \n",
    "    def extract_from_text(self, text):\n",
    "        \"\"\"\n",
    "        从文本中抽取三元组的主入口函数\n",
    "        \"\"\"\n",
    "        print(\"开始处理文本...\")\n",
    "        print(f\"文本长度: {len(text)} 字符\")\n",
    "        \n",
    "        # 1. 文本预处理\n",
    "        sentences = self.preprocess_text(text)\n",
    "        print(f\"分割为 {len(sentences)} 个句子\")\n",
    "        \n",
    "        all_triples = []\n",
    "        \n",
    "        # 2. 逐句处理\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            print(f\"\\n【处理第 {i+1} 句】\")\n",
    "            \n",
    "            # 分析句子结构\n",
    "            doc, dependency_info, root_token = self.analyze_sentence(sentence)\n",
    "            \n",
    "            # 打印依存分析结果（调试用）\n",
    "            self.print_dependency_info(dependency_info)\n",
    "            \n",
    "            # 抽取三元组\n",
    "            sentence_triples = self.extract_triples_by_rules(doc, root_token)\n",
    "            \n",
    "            print(f\"本句抽取到 {len(sentence_triples)} 个三元组\")\n",
    "            for triple in sentence_triples:\n",
    "                print(f\"  ✓ ({triple['subject']}, {triple['relation']}, {triple['object']}) [{triple['rule']}]\")\n",
    "            \n",
    "            all_triples.extend(sentence_triples)\n",
    "        \n",
    "        # 3. 后处理\n",
    "        final_triples = self.post_process_triples(all_triples)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"处理完成！共抽取 {len(final_triples)} 个唯一三元组\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        return final_triples\n",
    "    \n",
    "    def print_dependency_info(self, dependency_info):\n",
    "        \"\"\"\n",
    "        打印依存分析信息（用于调试）\n",
    "        \"\"\"\n",
    "        print(\"依存分析结果:\")\n",
    "        for info in dependency_info:\n",
    "            marker = \"★\" if info['is_root'] else \" \"\n",
    "            print(f\"  {marker} {info['text']}({info['pos']}) --{info['dep']}--> {info['head_text']}({info['head_pos']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56a4f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理文本...\n",
      "文本长度: 651 字符\n",
      "分割为 17 个句子\n",
      "\n",
      "【处理第 1 句】\n",
      "依存分析结果:\n",
      "    据(ADP) --case--> 报道(VERB)\n",
      "    外媒(NOUN) --nsubj--> 报道(VERB)\n",
      "    报道(VERB) --nmod:prep--> 坠毁(VERB)\n",
      "    ，(PUNCT) --punct--> 坠毁(VERB)\n",
      "    美国(PROPN) --nmod--> 军机(NOUN)\n",
      "    两(NUM) --nummod--> 军机(NOUN)\n",
      "    架(NUM) --mark:clf--> 两(NUM)\n",
      "    海军(NOUN) --compound:nn--> 军机(NOUN)\n",
      "    军机(NOUN) --nsubj--> 坠毁(VERB)\n",
      "    26日(NOUN) --nmod:tmod--> 坠毁(VERB)\n",
      "    分别(ADV) --advmod--> 坠毁(VERB)\n",
      "    坠毁(VERB) --ROOT--> 坠毁(VERB)\n",
      "    在(ADP) --case--> 南海(PROPN)\n",
      "    南海(PROPN) --nmod:prep--> 坠毁(VERB)\n",
      "    ，(PUNCT) --punct--> 坠毁(VERB)\n",
      "    无(VERB) --conj--> 坠毁(VERB)\n",
      "    人员(NOUN) --nsubj--> 伤亡(VERB)\n",
      "    伤亡(VERB) --ccomp--> 无(VERB)\n",
      "    。(PUNCT) --punct--> 坠毁(VERB)\n",
      "本句抽取到 1 个三元组\n",
      "  ✓ (美国两军机, 坠毁在, 南海) [PREP]\n",
      "\n",
      "【处理第 2 句】\n",
      "依存分析结果:\n",
      "    第一(NUM) --nummod--> 事件(NOUN)\n",
      "    起(NUM) --mark:clf--> 第一(NUM)\n",
      "    坠机(NOUN) --compound:nn--> 事件(NOUN)\n",
      "    事件(NOUN) --nsubj--> 涉及(VERB)\n",
      "    涉及(VERB) --ROOT--> 涉及(VERB)\n",
      "    一(NUM) --nummod--> 直升机(NOUN)\n",
      "    架(NUM) --mark:clf--> 一(NUM)\n",
      "    MH(PROPN) --compound:nn--> 直升机(NOUN)\n",
      "    -(PUNCT) --punct--> 60(NUM)\n",
      "    60(NUM) --dep--> R(NOUN)\n",
      "    R(NOUN) --compound:nn--> 直升机(NOUN)\n",
      "    海鹰(PROPN) --compound:nn--> 直升机(NOUN)\n",
      "    直升机(NOUN) --dobj--> 涉及(VERB)\n",
      "    。(PUNCT) --punct--> 涉及(VERB)\n",
      "本句抽取到 1 个三元组\n",
      "  ✓ (第一事件, 涉及, 一直升机) [SVO]\n",
      "\n",
      "【处理第 3 句】\n",
      "依存分析结果:\n",
      "    根据(ADP) --case--> 声明(NOUN)\n",
      "    美国(PROPN) --nmod:assmod--> 舰队(NOUN)\n",
      "    海军(NOUN) --compound:nn--> 舰队(NOUN)\n",
      "    太平洋(PROPN) --compound:nn--> 舰队(NOUN)\n",
      "    舰队(NOUN) --nmod:assmod--> 声明(NOUN)\n",
      "    的(PART) --case--> 舰队(NOUN)\n",
      "    声明(NOUN) --nmod:prep--> 坠入(VERB)\n",
      "    ，(PUNCT) --punct--> 坠入(VERB)\n",
      "    这(DET) --det--> 直升机(NOUN)\n",
      "    架(NUM) --mark:clf--> 这(DET)\n",
      "    直升机(NOUN) --nsubj--> 坠入(VERB)\n",
      "    在(ADP) --case--> 兹号(VERB)\n",
      "    尼米(NOUN) --nsubj--> 兹号(VERB)\n",
      "    兹号(VERB) --nmod:prep--> 坠入(VERB)\n",
      "    航空母舰(NOUN) --dobj--> 兹号(VERB)\n",
      "    进行(VERB) --conj--> 兹号(VERB)\n",
      "    例行(ADJ) --amod--> 操作(NOUN)\n",
      "    操作(NOUN) --dobj--> 进行(VERB)\n",
      "    时(PART) --case--> 兹号(VERB)\n",
      "    坠入(VERB) --ROOT--> 坠入(VERB)\n",
      "    南海(PROPN) --dobj--> 坠入(VERB)\n",
      "    。(PUNCT) --punct--> 坠入(VERB)\n",
      "本句抽取到 6 个三元组\n",
      "  ✓ (尼米, 兹号, 航空母舰) [SVO]\n",
      "  ✓ (直升机, 坠入, 南海) [SVO]\n",
      "  ✓ (直升机, 坠入根据, 声明) [PREP]\n",
      "  ✓ (直升机, 坠入的, 舰队) [PREP]\n",
      "  ✓ (尼米, 兹号在, 航空母舰) [PREP]\n",
      "  ✓ (尼米, 兹号时, 航空母舰) [PREP]\n",
      "\n",
      "【处理第 4 句】\n",
      "依存分析结果:\n",
      "    声明(NOUN) --nsubj--> 称(VERB)\n",
      "    称(VERB) --ROOT--> 称(VERB)\n",
      "    ，(PUNCT) --punct--> 称(VERB)\n",
      "    直升机(NOUN) --nmod--> 人员(NOUN)\n",
      "    上(PART) --case--> 直升机(NOUN)\n",
      "    的(PART) --case--> 直升机(NOUN)\n",
      "    三(NUM) --nummod--> 人员(NOUN)\n",
      "    名(NUM) --mark:clf--> 三(NUM)\n",
      "    机组(NOUN) --compound:nn--> 人员(NOUN)\n",
      "    人员(NOUN) --nsubjpass--> 救起(VERB)\n",
      "    被(X) --auxpass--> 救起(VERB)\n",
      "    搜救队(NOUN) --nsubj--> 救起(VERB)\n",
      "    救起(VERB) --ccomp--> 称(VERB)\n",
      "    。(PUNCT) --punct--> 称(VERB)\n",
      "本句抽取到 2 个三元组\n",
      "  ✓ (搜救队, 救起上, 直升机) [PREP]\n",
      "  ✓ (搜救队, 救起的, 直升机) [PREP]\n",
      "\n",
      "【处理第 5 句】\n",
      "依存分析结果:\n",
      "    半(NUM) --dep--> 小时(NOUN)\n",
      "    小时(NOUN) --advmod:loc--> 坠毁(VERB)\n",
      "    后(PART) --case--> 小时(NOUN)\n",
      "    ，(PUNCT) --punct--> 坠毁(VERB)\n",
      "    一(NUM) --nummod--> F(NOUN)\n",
      "    架(NUM) --mark:clf--> 一(NUM)\n",
      "    波音(PROPN) --compound:nn--> F(NOUN)\n",
      "    F(NOUN) --dep--> 战斗机(NOUN)\n",
      "    /(PUNCT) --punct--> 战斗机(NOUN)\n",
      "    A(X) --dep--> 战斗机(NOUN)\n",
      "    -(PRON) --punct--> 战斗机(NOUN)\n",
      "    18(NOUN) --dep--> F(X)\n",
      "    F(X) --dep--> 战斗机(NOUN)\n",
      "    超级(ADJ) --amod--> 大黄蜂(NOUN)\n",
      "    大黄蜂(NOUN) --compound:nn--> 战斗机(NOUN)\n",
      "    战斗机(NOUN) --nsubj--> 坠毁(VERB)\n",
      "    在(ADP) --case--> 兹号(VERB)\n",
      "    尼米(NOUN) --nsubj--> 兹号(VERB)\n",
      "    兹号(VERB) --nmod:prep--> 坠毁(VERB)\n",
      "    航空母舰(NOUN) --dobj--> 兹号(VERB)\n",
      "    执行(VERB) --conj--> 兹号(VERB)\n",
      "    例行(ADJ) --amod--> 任务(NOUN)\n",
      "    任务(NOUN) --dobj--> 执行(VERB)\n",
      "    时(PART) --case--> 兹号(VERB)\n",
      "    也(ADV) --advmod--> 坠毁(VERB)\n",
      "    坠毁(VERB) --ROOT--> 坠毁(VERB)\n",
      "    在(ADP) --case--> 南海(PROPN)\n",
      "    南海(PROPN) --nmod:prep--> 坠毁(VERB)\n",
      "    。(PUNCT) --punct--> 坠毁(VERB)\n",
      "本句抽取到 5 个三元组\n",
      "  ✓ (尼米, 兹号, 航空母舰) [SVO]\n",
      "  ✓ (战斗机, 坠毁后, 小时) [PREP]\n",
      "  ✓ (尼米, 兹号在, 航空母舰) [PREP]\n",
      "  ✓ (尼米, 兹号时, 航空母舰) [PREP]\n",
      "  ✓ (战斗机, 坠毁在, 南海) [PREP]\n",
      "\n",
      "【处理第 6 句】\n",
      "依存分析结果:\n",
      "    机上(NOUN) --compound:nn--> 人员(NOUN)\n",
      "    两(NUM) --nummod--> 人员(NOUN)\n",
      "    名(NUM) --mark:clf--> 两(NUM)\n",
      "    机组(NOUN) --compound:nn--> 人员(NOUN)\n",
      "    人员(NOUN) --nsubj--> 弹射(ADV)\n",
      "    成功(ADV) --advmod--> 弹射(ADV)\n",
      "    弹射(ADV) --ROOT--> 弹射(ADV)\n",
      "    逃生(VERB) --compound:vc--> 弹射(ADV)\n",
      "    ，(PUNCT) --punct--> 弹射(ADV)\n",
      "    被(X) --auxpass--> 救起(VERB)\n",
      "    安全(ADV) --advmod--> 救起(VERB)\n",
      "    救起(VERB) --conj--> 弹射(ADV)\n",
      "    。(PUNCT) --punct--> 弹射(ADV)\n",
      "本句抽取到 0 个三元组\n",
      "\n",
      "【处理第 7 句】\n",
      "依存分析结果:\n",
      "    据(ADP) --case--> 称(VERB)\n",
      "    美国(PROPN) --nmod:assmod--> 海军(NOUN)\n",
      "    海军(NOUN) --nsubj--> 称(VERB)\n",
      "    称(VERB) --ROOT--> 称(VERB)\n",
      "    ，(PUNCT) --punct--> 称(VERB)\n",
      "    所有(DET) --det--> 人员(NOUN)\n",
      "    相关(ADJ) --amod--> 人员(NOUN)\n",
      "    人员(NOUN) --nsubj--> 安全(VERB)\n",
      "    均(ADV) --advmod--> 安全(VERB)\n",
      "    安全(VERB) --ccomp--> 称(VERB)\n",
      "    且(CCONJ) --cc--> 安全(VERB)\n",
      "    情况(NOUN) --nsubj--> 稳定(VERB)\n",
      "    稳定(VERB) --conj--> 安全(VERB)\n",
      "    。(PUNCT) --punct--> 称(VERB)\n",
      "本句抽取到 0 个三元组\n",
      "\n",
      "【处理第 8 句】\n",
      "依存分析结果:\n",
      "    两(NUM) --nummod--> 原因(NOUN)\n",
      "    起(NUM) --mark:clf--> 两(NUM)\n",
      "    事故(NOUN) --compound:nn--> 原因(NOUN)\n",
      "    原因(NOUN) --nsubj--> 正在(ADV)\n",
      "    正在(ADV) --ROOT--> 正在(ADV)\n",
      "    调查(NOUN) --advmod:loc--> 正在(ADV)\n",
      "    中(PART) --case--> 调查(NOUN)\n",
      "    。(PUNCT) --punct--> 正在(ADV)\n",
      "本句抽取到 0 个三元组\n",
      "\n",
      "【处理第 9 句】\n",
      "依存分析结果:\n",
      "     (SPACE) --dep-->  (SPACE)\n",
      "    军事(NOUN) --compound:nn--> 专家(NOUN)\n",
      "    专家(NOUN) --appos--> 张军社(PROPN)\n",
      "    张军社(PROPN) --nsubj--> 接受(VERB)\n",
      "    27日(NOUN) --dep--> 接受(VERB)\n",
      "    接受(VERB) --advcl:loc--> 表示(VERB)\n",
      "    环球(NOUN) --compound:nn--> 时报(NOUN)\n",
      "    时报(NOUN) --compound:nn--> 采访(NOUN)\n",
      "    采访(NOUN) --dobj--> 接受(VERB)\n",
      "    时(PART) --case--> 接受(VERB)\n",
      "    表示(VERB) --ROOT--> 表示(VERB)\n",
      "    ，(PUNCT) --punct--> 表示(VERB)\n",
      "    美国(PROPN) --nsubj--> 坠毁(VERB)\n",
      "    在(ADP) --case--> 南海(PROPN)\n",
      "    南海(PROPN) --nmod:prep--> 坠毁(VERB)\n",
      "    一(NUM) --advmod:loc--> 坠毁(VERB)\n",
      "    天(NUM) --mark:clf--> 一(NUM)\n",
      "    内(PART) --case--> 一(NUM)\n",
      "    先后(ADV) --advmod--> 坠毁(VERB)\n",
      "    坠毁(VERB) --ccomp--> 表示(VERB)\n",
      "    一(NUM) --nummod--> 直升机(NOUN)\n",
      "    架(NUM) --mark:clf--> 一(NUM)\n",
      "    舰载(ADJ) --amod--> 战斗机(NOUN)\n",
      "    战斗机(NOUN) --conj--> 直升机(NOUN)\n",
      "    和(CCONJ) --cc--> 直升机(NOUN)\n",
      "    一(NUM) --nummod--> 直升机(NOUN)\n",
      "    架(NUM) --mark:clf--> 一(NUM)\n",
      "    直升机(NOUN) --dobj--> 坠毁(VERB)\n",
      "    ，(PUNCT) --punct--> 坠毁(VERB)\n",
      "    这(DET) --det--> 事件(NOUN)\n",
      "    一(NUM) --dep--> 这(DET)\n",
      "    事件(NOUN) --nsubj--> 偶然(NOUN)\n",
      "    并非(VERB) --cop--> 偶然(NOUN)\n",
      "    偶然(NOUN) --conj--> 坠毁(VERB)\n",
      "    。(PUNCT) --punct--> 表示(VERB)\n",
      "本句抽取到 5 个三元组\n",
      "  ✓ (张军社, 接受, 采访) [SVO]\n",
      "  ✓ (美国, 坠毁, 一一直升机) [SVO]\n",
      "  ✓ (张军社, 接受时, 采访) [PREP]\n",
      "  ✓ (美国, 坠毁在, 南海) [PREP]\n",
      "  ✓ (专家, 是, 张军社) [APPOS]\n",
      "\n",
      "【处理第 10 句】\n",
      "依存分析结果:\n",
      "    美军(NOUN) --nsubj--> 维持(VERB)\n",
      "    长期(ADV) --advmod--> 维持(VERB)\n",
      "    在(ADP) --case--> 范围(NOUN)\n",
      "    南海(PROPN) --conj--> 全球(NOUN)\n",
      "    、(PUNCT) --punct--> 全球(NOUN)\n",
      "    亚太(PROPN) --conj--> 全球(NOUN)\n",
      "    及(CCONJ) --cc--> 全球(NOUN)\n",
      "    全球(NOUN) --compound:nn--> 范围(NOUN)\n",
      "    范围(NOUN) --nmod:prep--> 维持(VERB)\n",
      "    内(PART) --case--> 范围(NOUN)\n",
      "    维持(VERB) --ROOT--> 维持(VERB)\n",
      "    高(ADJ) --amod--> 强度(NOUN)\n",
      "    强度(NOUN) --amod--> 状态(NOUN)\n",
      "    战备(NOUN) --compound:nn--> 状态(NOUN)\n",
      "    状态(NOUN) --dobj--> 维持(VERB)\n",
      "    ，(PUNCT) --punct--> 维持(VERB)\n",
      "    不断(ADV) --advmod--> 进行(VERB)\n",
      "    进行(VERB) --conj--> 维持(VERB)\n",
      "    军事(NOUN) --compound:nn--> 部署(NOUN)\n",
      "    部署(NOUN) --dobj--> 进行(VERB)\n",
      "    ，(PUNCT) --punct--> 维持(VERB)\n",
      "    以(PART) --aux:prtmod--> 维持(VERB)\n",
      "    维持(VERB) --conj--> 维持(VERB)\n",
      "    其(PRON) --compound:nn--> 地位(NOUN)\n",
      "    霸权(NOUN) --compound:nn--> 地位(NOUN)\n",
      "    地位(NOUN) --conj--> 角色(NOUN)\n",
      "    和(CCONJ) --cc--> 角色(NOUN)\n",
      "    国际(NOUN) --compound:nn--> 警察(NOUN)\n",
      "    警察(NOUN) --compound:nn--> 角色(NOUN)\n",
      "    角色(NOUN) --dobj--> 维持(VERB)\n",
      "    。(PUNCT) --punct--> 维持(VERB)\n",
      "本句抽取到 3 个三元组\n",
      "  ✓ (美军, 维持, 高强度状态) [SVO]\n",
      "  ✓ (美军, 维持在, 范围) [PREP]\n",
      "  ✓ (美军, 维持内, 范围) [PREP]\n",
      "\n",
      "【处理第 11 句】\n",
      "依存分析结果:\n",
      "    长期(ADJ) --amod--> 运作(NOUN)\n",
      "    高压(ADV) --advmod--> 运作(NOUN)\n",
      "    运作(NOUN) --nsubj--> 使(VERB)\n",
      "    使(VERB) --ROOT--> 使(VERB)\n",
      "    美军(NOUN) --compound:nn--> 兵力(NOUN)\n",
      "    兵力(NOUN) --dobj--> 使(VERB)\n",
      "    紧张(VERB) --ccomp--> 使(VERB)\n",
      "    、(PUNCT) --punct--> 紧张(VERB)\n",
      "    人员(NOUN) --nsubj--> 疲惫(VERB)\n",
      "    疲惫(VERB) --conj--> 紧张(VERB)\n",
      "    ，(PUNCT) --punct--> 使(VERB)\n",
      "    事故(NOUN) --nsubj--> 发生(VERB)\n",
      "    发生(VERB) --acl--> 风险(NOUN)\n",
      "    的(PART) --mark--> 发生(VERB)\n",
      "    风险(NOUN) --nsubj--> 上升(VERB)\n",
      "    自然(ADV) --advmod--> 上升(VERB)\n",
      "    随之(NOUN) --advmod--> 上升(VERB)\n",
      "    上升(VERB) --conj--> 使(VERB)\n",
      "    。(PUNCT) --punct--> 使(VERB)\n",
      "本句抽取到 1 个三元组\n",
      "  ✓ (长期运作, 使, 兵力) [SVO]\n",
      "\n",
      "【处理第 12 句】\n",
      "依存分析结果:\n",
      "    他(PRON) --nsubj--> 认为(VERB)\n",
      "    认为(VERB) --ROOT--> 认为(VERB)\n",
      "    ，(PUNCT) --punct--> 认为(VERB)\n",
      "    此次(ADV) --advmod--> 有关(VERB)\n",
      "    事故(NOUN) --nsubj--> 有关(VERB)\n",
      "    很(ADV) --advmod--> 有关(VERB)\n",
      "    可能(VERB) --aux:modal--> 有关(VERB)\n",
      "    与(ADP) --case--> 操作(VERB)\n",
      "    操作(VERB) --acl--> 因素(NOUN)\n",
      "    疏忽(NOUN) --dobj--> 操作(VERB)\n",
      "    或(CCONJ) --cc--> 疏忽(NOUN)\n",
      "    过度(ADV) --advmod--> 疲劳(VERB)\n",
      "    疲劳(VERB) --conj--> 疏忽(NOUN)\n",
      "    等(PART) --dep--> 操作(VERB)\n",
      "    因素(NOUN) --nmod:prep--> 有关(VERB)\n",
      "    有关(VERB) --ccomp--> 认为(VERB)\n",
      "    。(PUNCT) --punct--> 认为(VERB)\n",
      "本句抽取到 0 个三元组\n",
      "\n",
      "【处理第 13 句】\n",
      "依存分析结果:\n",
      "    军事(NOUN) --compound:nn--> 专家(NOUN)\n",
      "    专家(NOUN) --appos--> 宋忠平(PROPN)\n",
      "    宋忠平(PROPN) --nsubj--> 接受(VERB)\n",
      "    27日(NOUN) --nmod:tmod--> 接受(VERB)\n",
      "    接受(VERB) --advcl:loc--> 持(VERB)\n",
      "    环球(NOUN) --compound:nn--> 时报(NOUN)\n",
      "    时报(NOUN) --compound:nn--> 采访(NOUN)\n",
      "    采访(NOUN) --dobj--> 接受(VERB)\n",
      "    时(PART) --case--> 接受(VERB)\n",
      "    也(ADV) --advmod--> 持(VERB)\n",
      "    持(VERB) --ROOT--> 持(VERB)\n",
      "    相似(ADJ) --amod--> 观点(NOUN)\n",
      "    观点(NOUN) --dobj--> 持(VERB)\n",
      "    。(PUNCT) --punct--> 持(VERB)\n",
      "本句抽取到 3 个三元组\n",
      "  ✓ (宋忠平, 接受, 采访) [SVO]\n",
      "  ✓ (宋忠平, 接受时, 采访) [PREP]\n",
      "  ✓ (专家, 是, 宋忠平) [APPOS]\n",
      "\n",
      "【处理第 14 句】\n",
      "依存分析结果:\n",
      "    他(PRON) --nsubj--> 指出(VERB)\n",
      "    指出(VERB) --ROOT--> 指出(VERB)\n",
      "    ，(PUNCT) --punct--> 指出(VERB)\n",
      "    美军(NOUN) --nsubj--> 为(VERB)\n",
      "    长期(ADV) --advmod--> 为(VERB)\n",
      "    以(ADP) --case--> 自由(NOUN)\n",
      "    所谓(ADJ) --amod--> 自由(NOUN)\n",
      "    航行(VERB) --amod--> 自由(NOUN)\n",
      "    自由(NOUN) --nmod:prep--> 为(VERB)\n",
      "    为(VERB) --ccomp--> 指出(VERB)\n",
      "    借口(NOUN) --dobj--> 为(VERB)\n",
      "    ，(PUNCT) --punct--> 为(VERB)\n",
      "    在(ADP) --case--> 南海(PROPN)\n",
      "    南海(PROPN) --nmod:prep--> 炫耀(VERB)\n",
      "    频繁(ADV) --advmod--> 炫耀(VERB)\n",
      "    炫耀(VERB) --conj--> 为(VERB)\n",
      "    武力(NOUN) --dobj--> 炫耀(VERB)\n",
      "    ，(PUNCT) --punct--> 为(VERB)\n",
      "    意在(VERB) --conj--> 为(VERB)\n",
      "    彰显(VERB) --ccomp--> 意在(VERB)\n",
      "    其(PRON) --nmod:poss--> 军事(NOUN)\n",
      "    军事(NOUN) --compound:nn--> 存在(NOUN)\n",
      "    存在(NOUN) --dobj--> 意在(VERB)\n",
      "    。(PUNCT) --punct--> 指出(VERB)\n",
      "本句抽取到 2 个三元组\n",
      "  ✓ (美军, 为, 借口) [SVO]\n",
      "  ✓ (美军, 为以, 所谓航行自由) [PREP]\n",
      "\n",
      "【处理第 15 句】\n",
      "依存分析结果:\n",
      "    表面(NOUN) --advmod:loc--> 看(VERB)\n",
      "    上(PART) --case--> 表面(NOUN)\n",
      "    看(VERB) --ROOT--> 看(VERB)\n",
      "    ，(PUNCT) --punct--> 维持(VERB)\n",
      "    美国(PROPN) --nsubj--> 维持(VERB)\n",
      "    作为(ADP) --case--> 霸主(NOUN)\n",
      "    军事(NOUN) --compound:nn--> 霸主(NOUN)\n",
      "    霸主(NOUN) --nmod:prep--> 维持(VERB)\n",
      "    仍(ADV) --advmod--> 在(ADV)\n",
      "    在(ADV) --advmod--> 维持(VERB)\n",
      "    维持(VERB) --dep--> 力不从心(VERB)\n",
      "    强势(NOUN) --compound:nn--> 姿态(NOUN)\n",
      "    姿态(NOUN) --dobj--> 维持(VERB)\n",
      "    ，(PUNCT) --punct--> 力不从心(VERB)\n",
      "    但(ADV) --advmod--> 力不从心(VERB)\n",
      "    实际上(ADV) --advmod--> 力不从心(VERB)\n",
      "    ，(PUNCT) --punct--> 力不从心(VERB)\n",
      "    即便(ADV) --advmod--> 拥有(VERB)\n",
      "    拥有(VERB) --dep--> 力不从心(VERB)\n",
      "    11(NUM) --nummod--> 航空母舰(NOUN)\n",
      "    艘(NUM) --mark:clf--> 11(NUM)\n",
      "    航空母舰(NOUN) --dobj--> 拥有(VERB)\n",
      "    ，(PUNCT) --punct--> 拥有(VERB)\n",
      "    面对(VERB) --conj--> 拥有(VERB)\n",
      "    如此(ADV) --advmod--> 繁重(ADJ)\n",
      "    繁重(ADJ) --amod--> 任务(NOUN)\n",
      "    的(PART) --case--> 繁重(ADJ)\n",
      "    任务(NOUN) --dobj--> 面对(VERB)\n",
      "    ，(PUNCT) --punct--> 力不从心(VERB)\n",
      "    美军(NOUN) --nsubj--> 力不从心(VERB)\n",
      "    也(ADV) --advmod--> 力不从心(VERB)\n",
      "    已(ADV) --advmod--> 力不从心(VERB)\n",
      "    力不从心(VERB) --ccomp--> 看(VERB)\n",
      "    。(PUNCT) --punct--> 看(VERB)\n",
      "本句抽取到 2 个三元组\n",
      "  ✓ (美国, 维持, 姿态) [SVO]\n",
      "  ✓ (美国, 维持作为, 霸主) [PREP]\n",
      "\n",
      "【处理第 16 句】\n",
      "依存分析结果:\n",
      "    宋忠平(PROPN) --nsubj--> 分析(VERB)\n",
      "    分析(VERB) --ROOT--> 分析(VERB)\n",
      "    称(VERB) --compound:vc--> 分析(VERB)\n",
      "    ，(PUNCT) --punct--> 分析(VERB)\n",
      "    美军(NOUN) --compound:nn--> 航母(NOUN)\n",
      "    航母(NOUN) --nsubj--> 肩负(VERB)\n",
      "    肩负(VERB) --conj--> 分析(VERB)\n",
      "    全球(NOUN) --compound:nn--> 部署(NOUN)\n",
      "    部署(NOUN) --dobj--> 肩负(VERB)\n",
      "    和(CCONJ) --cc--> 任务(NOUN)\n",
      "    多重(ADJ) --amod--> 任务(NOUN)\n",
      "    任务(NOUN) --dobj--> 肩负(VERB)\n",
      "    ，(PUNCT) --punct--> 肩负(VERB)\n",
      "    长期(ADV) --advmod--> 存在(VERB)\n",
      "    在(ADP) --case--> 强度(NOUN)\n",
      "    中东(PROPN) --conj--> 地区(NOUN)\n",
      "    及(CCONJ) --cc--> 地区(NOUN)\n",
      "    其他(DET) --det--> 地区(NOUN)\n",
      "    地区(NOUN) --compound:nn--> 强度(NOUN)\n",
      "    高(ADJ) --amod--> 强度(NOUN)\n",
      "    强度(NOUN) --compound:nn--> 训练(NOUN)\n",
      "    执行(NOUN) --compound:nn--> 训练(NOUN)\n",
      "    作战(NOUN) --conj--> 训练(NOUN)\n",
      "    和(CCONJ) --cc--> 训练(NOUN)\n",
      "    训练(NOUN) --dep--> 长期(ADV)\n",
      "    ，(PUNCT) --punct--> 存在(VERB)\n",
      "    加之(ADV) --advmod--> 存在(VERB)\n",
      "    部分(NUM) --dep--> 官兵(NOUN)\n",
      "    官兵(NOUN) --nsubj--> 存在(VERB)\n",
      "    存在(VERB) --conj--> 肩负(VERB)\n",
      "    懈怠(NOUN) --conj--> 情绪(NOUN)\n",
      "    、(PUNCT) --punct--> 情绪(NOUN)\n",
      "    厌战(NOUN) --compound:nn--> 情绪(NOUN)\n",
      "    情绪(NOUN) --dobj--> 存在(VERB)\n",
      "    ，(PUNCT) --punct--> 存在(VERB)\n",
      "    导致(VERB) --conj--> 存在(VERB)\n",
      "    安全(NOUN) --compound:nn--> 风险(NOUN)\n",
      "    风险(NOUN) --nsubj--> 上升(VERB)\n",
      "    上升(VERB) --ccomp--> 导致(VERB)\n",
      "    。(PUNCT) --punct--> 分析(VERB)\n",
      "本句抽取到 3 个三元组\n",
      "  ✓ (航母, 肩负, 部署) [SVO]\n",
      "  ✓ (航母, 肩负, 多重任务) [SVO]\n",
      "  ✓ (官兵, 存在, 情绪) [SVO]\n",
      "\n",
      "【处理第 17 句】\n",
      "依存分析结果:\n",
      "    因此(ADV) --advmod--> 发生(VERB)\n",
      "    ，(PUNCT) --punct--> 发生(VERB)\n",
      "    同一天(NOUN) --nsubj--> 发生(VERB)\n",
      "    发生(VERB) --ROOT--> 发生(VERB)\n",
      "    两(NUM) --nummod--> 事故(NOUN)\n",
      "    起(NUM) --mark:clf--> 两(NUM)\n",
      "    坠机(NOUN) --compound:nn--> 事故(NOUN)\n",
      "    事故(NOUN) --dobj--> 发生(VERB)\n",
      "    虽(SCONJ) --advmod--> 令(VERB)\n",
      "    令(VERB) --conj--> 发生(VERB)\n",
      "    人(NOUN) --dobj--> 令(VERB)\n",
      "    震惊(VERB) --ccomp--> 令(VERB)\n",
      "    ，(PUNCT) --punct--> 发生(VERB)\n",
      "    但(ADV) --advmod--> 令(VERB)\n",
      "    并(ADV) --advmod--> 令(VERB)\n",
      "    不(ADV) --neg--> 令(VERB)\n",
      "    令(VERB) --conj--> 发生(VERB)\n",
      "    人(NOUN) --dobj--> 令(VERB)\n",
      "    意外(VERB) --ccomp--> 令(VERB)\n",
      "    。(PUNCT) --punct--> 发生(VERB)\n",
      "本句抽取到 1 个三元组\n",
      "  ✓ (同一天, 发生, 两事故) [SVO]\n",
      "\n",
      "============================================================\n",
      "处理完成！共抽取 32 个唯一三元组\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "model = DependencyTripleExtractor()\n",
    "sentences = model.preprocess_text(text1)\n",
    "doc, dependency_info, root_token = model.analyze_sentence(sentences[3])\n",
    "material1_triples = model.extract_from_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf2324b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "词: 李克强, 依存关系: nmod:assmod, 父节点: 总理\n",
      "词: 总理, 依存关系: nsubj, 父节点: 我家\n",
      "词: 今天, 依存关系: nmod:tmod, 父节点: 我家\n",
      "词: 来, 依存关系: xcomp, 父节点: 我家\n",
      "词: 我家, 依存关系: ROOT, 父节点: 我家\n",
      "词: 了, 依存关系: dep, 父节点: 我家\n",
      "词: ,, 依存关系: punct, 父节点: 我家\n",
      "词: 我, 依存关系: nsubj, 父节点: 感到\n",
      "词: 感到, 依存关系: conj, 父节点: 我家\n",
      "词: 非常, 依存关系: advmod, 父节点: 荣幸\n",
      "词: 荣幸, 依存关系: ccomp, 父节点: 感到\n"
     ]
    }
   ],
   "source": [
    "doc, dependency_info, root_token = model.analyze_sentence(\"李克强总理今天来我家了,我感到非常荣幸\")\n",
    "doc, dependency_info, root_token = model.analyze_sentence(doc)\n",
    "triples = model.extract_preposition_triples(doc)\n",
    "print(triples)\n",
    "for token in doc:\n",
    "    print(f\"词: {token.text}, 依存关系: {token.dep_}, 父节点: {token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a9c0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m doc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mnlp(sentences[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m dependency_info:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m词: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 依存关系: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;241m.\u001b[39mdep_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 父节点: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# 查看依存关系\n",
    "doc = model.nlp(sentences[0])\n",
    "for token in doc:\n",
    "    print(f\"词: {token.text}, 依存关系: {token.dep_}, 父节点: {token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53dfc1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'据外媒报道，美国两架海军军机26日分别坠毁在南海，无人员伤亡。'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3cec49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
