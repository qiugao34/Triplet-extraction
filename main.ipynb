{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07bbd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_text(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"文本预处理：清洗、分句、去除无关字符\"\"\"\n",
    "    # 分句\n",
    "    sentences = re.split(r'(?<=[。！？\\?])', text)\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 5]\n",
    "    \n",
    "    # 清洗\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # 去除引号、括号等字符\n",
    "        cleaned = re.sub(r'[《》“”\\n（）()]', '', sentence)\n",
    "        cleaned_sentences.append(cleaned)\n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87935622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['据外媒报道，美国两架海军军机26日分别坠毁在南海，无人员伤亡。',\n",
       " '第一起坠机事件涉及一架MH-60R海鹰直升机。',\n",
       " '根据美国海军太平洋舰队的声明，这架直升机在尼米兹号航空母舰进行例行操作时坠入南海。',\n",
       " '声明称，直升机上的三名机组人员被搜救队救起。',\n",
       " '半小时后，一架波音F/A-18F超级大黄蜂战斗机在尼米兹号航空母舰执行例行任务时也坠毁在南海。',\n",
       " '机上两名机组人员成功弹射逃生，被安全救起。',\n",
       " '据美国海军称，所有相关人员均安全且情况稳定。',\n",
       " '两起事故原因正在调查中。',\n",
       " ' 军事专家张军社27日接受环球时报采访时表示，美国在南海一天内先后坠毁一架舰载战斗机和一架直升机，这一事件并非偶然。',\n",
       " '美军长期在南海、亚太及全球范围内维持高强度战备状态，不断进行军事部署，以维持其霸权地位和国际警察角色。',\n",
       " '长期高压运作使美军兵力紧张、人员疲惫，事故发生的风险自然随之上升。',\n",
       " '他认为，此次事故很可能与操作疏忽或过度疲劳等因素有关。',\n",
       " '军事专家宋忠平27日接受环球时报采访时也持相似观点。',\n",
       " '他指出，美军长期以所谓航行自由为借口，在南海频繁炫耀武力，意在彰显其军事存在。',\n",
       " '表面上看，美国作为军事霸主仍在维持强势姿态，但实际上，即便拥有11 艘航空母舰，面对如此繁重的任务，美军也已力不从心。',\n",
       " '宋忠平分析称，美军航母肩负全球部署和多重任务，长期在中东及其他地区高强度执行作战和训练，加之部分官兵存在懈怠、厌战情绪，导致安全风险上升。',\n",
       " '因此，同一天发生两起坠机事故虽令人震惊，但并不令人意外。']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = read_text(\"text1.txt\")\n",
    "preprocess_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50746015",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjieba\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjieba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mposseg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpseg\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class DependencyTripleExtractor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"zh_core_web_sm\")\n",
    "        # 加载领域词典\n",
    "        # self.load_domain_dictionary()\n",
    "        \n",
    "        # 初始化关系映射规则\n",
    "        self.init_relation_relus()\n",
    "    \n",
    "    def init_relation_relus(self):\n",
    "        \"\"\"初始化依存关系到语义关系的映射规则\"\"\"\n",
    "        # 基础依存关系映射\n",
    "        self.dep_to_relation = {\n",
    "            'nsubj': '',  # 主语，使用动词本身\n",
    "            'dobj': '',   # 宾语，使用动词本身\n",
    "            'nmod:poss': '的',  # 属格关系\n",
    "            'prep': '',   # 介词，与动词组合\n",
    "            'pobj': '',   # 介词宾语\n",
    "            'appos': '是',  # 同位语关系\n",
    "            'amod': '',   # 形容词修饰\n",
    "            'nummod': ''  # 数量修饰\n",
    "        }\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"文本预处理：清洗、分句、去除无关字符\"\"\"\n",
    "        # 分句\n",
    "        sentences = re.split(r'(?<=[。！？\\?])', text)\n",
    "        sentences = [s.strip() for s in sentences if len(s.strip()) > 5]\n",
    "        \n",
    "        # 清洗\n",
    "        cleaned_sentences = []\n",
    "        for sentence in sentences:\n",
    "            # 去除引号、括号等字符\n",
    "            cleaned = re.sub(r'[《》“”\\n（）()]', '', sentence)\n",
    "            cleaned_sentences.append(cleaned)\n",
    "        return cleaned_sentences\n",
    "    \n",
    "    def analyze_sentence(self, sentence):\n",
    "        \"\"\"分析句子结构：分词、词性标注、依存句法分析\"\"\"\n",
    "        # 实验spacy进行依存分析\n",
    "        doc = self.nlp(sentence)\n",
    "        \n",
    "        # 构建依存关系图\n",
    "        dependency_info = []\n",
    "        root_token = None\n",
    "        for token in doc:\n",
    "            dep_info = {\n",
    "                'text': token.text,\n",
    "                'lemma': token.lemma_,\n",
    "                'pos': token.pos_,\n",
    "                'dep': token.dep_,\n",
    "                'head_text': token.head.text,\n",
    "                'head_pos': token.head.pos_,\n",
    "                'is_root': token.dep == 'ROOT'\n",
    "            }\n",
    "            dependency_info.append(dep_info)\n",
    "            if token.dep == 'ROOT':\n",
    "                root_token = token\n",
    "        return doc, dependency_info, root_token\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4f51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
